# Perceptual Losses for Real-Time Style Transfer and Super-Resolution

## Abstract

parallel work has shown that high-quality images can be generated by defining and optimizing perceptual loss functions based on high-level features extracted from pretrained networks

## Introduction

- One approach for solving image transformation task is to train a feed-forward convolutional neural network in a supervised manner, using a per-pixel loss funciton to measure the difference between output and ground-truth

- high-quality images can be generated using perceptual loss functions based not on differences between pixels but instead of differences between high-level image feature representations extracted from pretrained convolutional neural networks

  - feature inversion
  - style transfer (Gatys et al)
  - texture synthesis

  > these approaches produce high-quality images, but are slow since inference requires solving an optimization problem

- we combine the benefits of these two approaches

  - train feed-forward transformation networks for image transformation tasks
  - but rather than using per-pixel loss functions depending only on low-level pixel information
  - train our netoworks using perceptual loss functions that depend on high-level features from a pretrained loss network

- experiment (style transfer)

  - there is no single correct output
  - requires semantic reasoning about the input image
    - the output must be semantically similar to the input despite drastic changes in color and texture
  - our feed-forward networks are trained to solve the optimization problem from Neural Algorithm of Style Transfer

## Method

2 components

- image transformation network (Resnet-Like)
  - faster if the network is trained well
- loss network (VGG16-Like)
  - better effect

> in general, we train a nerual network to make style transfer, what we optimize is not per-pixel loss but perceptual loss computed by another network, which is similar to Neural Style Transfer





