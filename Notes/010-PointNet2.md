# PointNet++

## Introduction

我们着重于讨论位于欧几里得空间中的点云数据，明显的特点是之于所有点的排列顺序的不敏感

PointNet 的基本思想是学习之于每个点的编码方式，然后将每个孤立的点特征聚集起来从而得到全局特征，不过如此以来将无法捕获由度量（metric）所定义的局部结构，而根据 CNN 的成功可以证明局部特征的重要性，即通过随着结构逐步地提取局部模式能提升泛化能力

<blockquote alt="warn">
    <p>
        距离度量所定义的局部领域可能表现出不同的属性，例如密度和其它属性在不同的位置可能是不一致的
    </p>
</blockquote>

PointNet++ 非常简单

1. 通过特定度量空间（metric space）下的距离度量将点集中的所有点划分为若干个重叠的局部区域
2. 类似于 CNNs，我们从小邻域中提取捕获了几何结构的局部特征，部分的局部特征被聚集到更大的单元中从而生成更高级别的特征
3. 重复步骤 2 的方法直到我们获得了整个点集的特征

## Structure

我们的新模型构建了一个层次化的点簇，而且可以随着模型逐步地提取越来越大的局部区域，模型由一系列的集合抽象层级（Set Abstraction Levels）构成，在每个层级中，一系列的点被运算和提取以生成一个具有较少元素的集合，一个集合抽象层级由以下 3 个关键部分构成

- 采样层（Sampling Layer）：从输入中选择一系列的点，这些点决定了局部区域的质心
- 聚集层（Grouping Layer）：通过寻找质心周围的"相邻"点来构建局部区域
- PointNet：利用 PointNet 将局部区域编码为特征向量

### 采样层

采样层利用迭代的最远点采样（Farthest Point Sampling, FPS）来选择一个子集

1. 被采样的点的个数（质心的个数）是确定好的
2. 每个质心总是距离已经确定好的所有质心最远的点（相对于剩余的点来说）
3. 距离的计算方法依赖于点集所在的空间（默认情况下是欧几里得坐标系）

<blockquote alt="success">
    <p>
        和随机采样相比，在给定相同数量质心的情况下，最远点采样在整个点集上有更好的覆盖率
    </p>
</blockquote>

和卷积神经网络中通过固定步长来遍历数据从而实现采样的方式不同，我们的采样方法以数据依赖的方式生成感受野（每个质心都依赖于之前已经确定好的质心）

### 聚集层

利用球采样（Ball Query）的方式查找以质心为球心在特定半径范围内的点，从而构成一个簇（每个簇中的点的数量上限是 $K$ 个）

1. 输入包含 $N$ 个点以及 $N^{'}$ 个质心坐标
2. 输出包含 $N^{'}$ 个簇，每个簇中有 $K$ 个点
3. 距离的计算方法任然依赖于点集所在的空间

每个点以 $(d + C)$ 的形式描述，$d$ 表示 $d$ 维的坐标，$C$ 表示 $C$ 维的点特征

<blockquote alt="danger">
    <p>
        必须注意的是，<i>K</i> 在不同簇中的大小是不同的（或许和不同区域的密集度有关系），不过后续的 PointNet Layer 有能力将任意个数的点转换到特定长度的局部特征向量中
    </p>
</blockquote>
### PointNet

利用 PointNet 将每个区域（包含质心以及若干个相邻的点，每个点由坐标和特征构成）编码

1. 在学习之前，将相邻坐标转换为相对于质心的局部坐标
2. 将 PointNet 作为局部特征学习的基本构建块

<blockquote alt="info">
    <p>
        利用相对坐标可以在局部区域捕获点到点的联系
    </p>
</blockquote>
## Multi-scale

点云的非均匀分布为特征学习带来了挑战：在稠密点云数据上学习到的特征可能无法泛化到稀疏采样的区域，而在稀疏点云上训练的模型或许无法辨识细粒度的局部结构

理想情况下，我们希望尽可能地检查在稠密采样区域的点以捕获到最好的细节，不过在稀疏区域显然是不可行，原因在于采样性不足可能导致局部模式被破坏

在这种情况下，我们应该在大的邻域中（和原来的范围相比）寻找大尺度的特征，为了实现此目标，我们想出了密度自适应的 PointNet 层以学习在输入采样密度发生变化的时候将不同规模区域的特征组合起来

采用了密度自适应的 PointNet 被称为 PointNet++，在 PointNet++ 中，每个抽象层级提取多尺度的局部模式且根据局部点的密度智能地将它们组合在一起，有两种不同类型的密度自适应方法

### MSG(Multi-Scale Grouping)

捕获多尺度模式的一个简单却行之有效的办法是应用不同尺度的聚集层，再让 PointNet 提取不同尺度的特征，最后再将它们组合起来

为了让多尺度特征被有效地学习，之于每个实例，我们以随机的概率随机地丢弃一些输入点

1. 从 $[0,p]$ 中均匀地采样一个 $\theta$ 作为丢弃率（Dropout Ratio）
2. 我们根据丢弃率随机地选择是否保留某个点

<blockquote alt="info">
    <p>
        在训练时选择 0.95 作为 <i>p</i> 的值以避免生成空集
    </p>
</blockquote>

<blockquote alt="success">
    <p>
        通过此方法，我们可以让模型在不同的稀疏度和不同的一致性下训练以获得更好的表现力
    </p>
</blockquote>

### MRG(Multi-Resolution Grouping)

上述方法在计算方面有很大的开销，原因在于之于每个质心都要计算大规模邻域的特征，而在较低级别的抽象层级中存在很多数量的质心，尤其在最低级别的部分，所以我们想出了另一种方案去避免高昂的计算开销，不过任然保留了根据点的分布性特征去自适应聚合信息的能力

<blockquote alt="success">
    <P>
        和 MSG 相比，由于我们避免了较低级别的规模邻域的特征提取，所以在计算方面是高效的
    </P>
</blockquote>
